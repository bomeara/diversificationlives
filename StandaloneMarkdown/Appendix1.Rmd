---
title: "Appendix 1"
author: "Brian O'Meara & Jeremy Beaulieu"
date: "6/30/2020"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, cache=FALSE, fig.width=7, fig.height=5)
set.seed(1859)
```

## Functionally congruent coin models

Coin flipping models are popular examples to use for statistics. Here we create models that imply very different things about coins, but have indistinguishable likelihoods at the precision commonly used in phylogenetics (hundredths of log likelihood units).

First start with the simple binomial model:

```{r simple, echo=TRUE, eval=FALSE}
coin_simple_likelihood <- function(x, nheads, nflips) {
  return(dbinom(nheads, nflips, x[1])) 
}
```

However, we can also have models that give a different probability of heads with every flip changing smoothly according to a function. Maybe we wear down the face of the coin every time we flip it so it is less and less likely to land on the lighter face.


```{r linear, echo=TRUE, eval=FALSE}
coin_linear_prob <- function(x, fixed.slope=0.1, nheads, nflips) {
  probabilities <- fixed.slope*sequence(nflips)/nflips + x[1]
  return(probabilities)
}
```

We can make several different models with different `fixed.slope`: one increases the probability of heads with every flip, another decreases, for example. But for each we can fit `x[1]`, the probability of heads before any flips. 

Since the probability of heads can change with every flip, calculating the probability of an observed proportion of heads in a set of flips requires computing the probability of all ways to get there: 2 heads of 3 flips could be HHT, HTH, THH, and each of these has a different probability. 

```{r linear_likelihood, echo=TRUE, eval=FALSE}
coin_linear_likelihood <- function(x, nheads, nflips, fixed.slope=0.1, neg=FALSE) {
  probabilities <- coin_linear_prob (x=x, nheads=nheads, nflips=nflips, fixed.slope=fixed.slope)
  if(any(probabilities>1 | probabilities<0)) {
    return(-1e8)
  }
  totalheadsprobs <- rep(0, nflips+1) #so it goes from 0 to nflips total heads
  for (i in seq_along(probabilities)){
    probhead <- probabilities[i]
    probtail <- 1-probhead
    if(i==1) {
      totalheadsprobs[0+1] <- probtail
      totalheadsprobs[1+1] <- probhead
    } else {
      totalheadsprobs <- totalheadsprobs*probtail + c(0,totalheadsprobs[1:(length(totalheadsprobs)-1)]*probhead)
    }
  }
  return(ifelse(neg, -1, 1)*totalheadsprobs[nheads+1])
}

coin_exponential_prob <- function(halflife, nheads, nflips) {
  lambda <- log(2)/halflife
  pheads <- 1*exp(-lambda*seq(from=1, to=nflips, by=1)) #by not starting at exp(-lambda * 0), it allows for something that has no heads on the first flip to have positive probability
  return(pheads)
}

get_possibilities <- function(heads, flips) {
 if(flips>25) {
    stop("Too many flips for the expand.grid silly approach to work")
 } 
  possibilities <- expand.grid(rep(list(c(0,1)),flips))
  possibilities <- possibilities[rowSums(possibilities)==heads,]
  return(possibilities)
}

coin_exponential_likelihood <- function(halflife, nheads, nflips, neg=FALSE, possibilities=get_possibilities(heads=nheads, flips=nflips)) {
  
  pheads <- coin_exponential_prob(halflife, nheads, nflips)
  ptails <- 1-pheads
  prob_matrix <- rbind(ptails, pheads) # heads = 1, tails =0, so when we offset, tails is first row, heads second
  
  likelihood <- 0
  for (i in sequence(nrow(possibilities))) {
    positions <- as.numeric(possibilities[i,]+1)
    local_prob <- 1
    for (j in sequence(ncol(possibilities))) {
      local_prob <- local_prob * unname(prob_matrix[positions[j],j])
    }
    likelihood <- likelihood + local_prob
  }
  print(c(halflife, likelihood))
  return(ifelse(neg, -1, 1)*likelihood)
}
```

Now let's simulate some data:

```{r simdata, echo=TRUE, eval=FALSE}
nflips <- 100
pheads <- 0.3
nheads <- rbinom(n=1, size=nflips, prob=pheads)
```

And fit it to three models: one with a constant estimated probability of heads, one with a linear increase in probability of heads with each flip (so by the end the probability of heads is 10% higher than when it started)  

```{r fit, echo=FALSE, eval=FALSE}
fixed.slope.increase = 0.1
fixed.slope.decrease = -0.05

#optimize isn't always great, so we first zoom in on the relevant area of parameter space

#Simple
x <- seq(from=0, to=1, length.out=10000)
y <- sapply(x, coin_simple_likelihood, nheads=nheads , nflips=nflips)
fit.df <- data.frame(parameter=x, probability=y, model="simple")
simple <- optimize(coin_simple_likelihood, interval=c(x[max(1,which.max(y)-20)], x[min(length(x),which.max(y)+20)]), nheads=nheads, nflips=nflips, maximum=TRUE, tol=1e-10)
```

```{r fit2, echo=FALSE, eval=FALSE}

# Increasing
x <- seq(from=-1.5, to=1, length.out=10000)
y <- sapply(x, coin_linear_likelihood, nheads=nheads , nflips=nflips, fixed.slope=fixed.slope.increase)
linear_increase <- optimize(coin_linear_likelihood, interval=c(x[max(1,which.max(y)-1000)], x[min(length(x),which.max(y)+1000)]), nheads=nheads, nflips=nflips,fixed.slope=fixed.slope.increase, maximum=TRUE, tol=1e-10)
fit.df <- rbind(fit.df, data.frame(parameter=x[y>0], probability=y[y>0], model="linear_increase"))

# Decreasing

#x <- seq(from=-1.5, to=1, length.out=10000)
#y <- sapply(x, coin_linear_likelihood, nheads=nheads , nflips=nflips, fixed.slope=fixed.slope.decrease)
#linear_decrease <- optimize(coin_linear_likelihood, interval=c(x[max(1,which.max(y)-1000)], x[min(length(x),which.max(y)+1000)]), nheads=nheads, nflips=nflips,fixed.slope=fixed.slope.decrease, maximum=TRUE, tol=1e-10)
#fit.df <- rbind(fit.df, data.frame(parameter=x[y>0], probability=y[y>0], model="linear_decrease"))
```

```{r fit3, echo=FALSE, eval=FALSE, eval=FALSE}

# Exponential

x <- seq(from=0.000001, to=2*nheads, length.out=25)
possibilities <- get_possibilities(heads=nheads, flips=nflips)
y <- sapply(x, coin_exponential_likelihood, nheads=nheads , nflips=nflips, possibilities=possibilities)
```

```{r fit4, echo=FALSE, eval=FALSE}


exponential_fit <- optimize(coin_exponential_likelihood, interval=c(max(0.01,x[which.max(y)-2]),min(6,x[which.max(y)]+2)), nheads=nheads, nflips=nflips,possibilities=possibilities, maximum=TRUE)
fit.df <- rbind(fit.df, data.frame(parameter=x[y>0], probability=y[y>0], model="exponential_decay"))


```

```{r results, eval=FALSE}
library(knitr)
#result.table <- data.frame(Model=c("Simple", "Linear 10%", "Exponential decay"), LogLikelihood = log(c(simple$objective, linear_increase$objective, exponential_fit$objective)), MLE=c(simple$maximum, linear_increase$maximum, exponential_fit$maximum), stringsAsFactors=FALSE)
result.table <- data.frame(Model=c("Simple", "Linear 10%"), LogLikelihood = round(log(c(simple$objective, linear_increase$objective)),2), MLE=c(simple$maximum, linear_increase$maximum), stringsAsFactors=FALSE)
knitr::kable(result.table, digits=3)
```

And we can plot the results

```{r plots, warning=FALSE, echo=FALSE,message=FALSE, eval=FALSE}
library(ggplot2)
# print(c("simple", simple$objective))
# print(c("linear_increase", linear_increase$objective))
# print(c("linear_decrease", linear_decrease$objective))

probability.df <- rbind(
  data.frame(flip=sequence(nflips), probability=simple$maximum, model="simple"),
  data.frame(flip=sequence(nflips), probability=.1*sequence(nflips)/nflips + linear_increase$maximum, model="Linear Increase")
  #data.frame(flip=sequence(nflips), probability=-.05*sequence(nflips)/nflips + exponential_fit$maximum, model="exponential_decay")
)

prob.plot <- ggplot(data=probability.df, aes(x=flip, y=probability, group=model)) + geom_smooth(aes(colour=model)) + ylab("Probability of heads for that flip") + xlab("Flip") + scale_colour_viridis_d(end=0.8)
print(prob.plot)

fit.plot <- ggplot(data=fit.df, aes(x=parameter, y=probability, group=model)) + geom_line(aes(colour=model)) + ylab("Probability of observed data") + xlab("Probability of heads before flipping") + scale_colour_viridis_d(end=0.8)

print(fit.plot)
```

## Diversification Signal

An open question in Louca and Pennell (2020) is the status of SSE models, such as BiSSE, MuSSE, HiSSE, and more. To examine this, we computed two trees with equal lineage through time plots. They have the same backbone tree, but then one replaces every tip with a balanced tree of four taxa ((A,B),(C,D)), and one uses a pectinate tree (A,(B,(C,D))).

```{r misseprep}
library(hisse)
library(ape)
library(TreePar)
library(geiger)
phy1 <- ape::compute.brlen(ape::stree(4, type="balanced"))
phy2 <- ape::compute.brlen(ape::stree(4, type="left"))
scale_factor <- 0.5
phy1$edge.length[1:3] <- c(1,2,2)/3
phy1$edge.length <- scale_factor * phy1$edge.length
phy2$edge.length <- scale_factor * phy2$edge.length


power = 5
set.seed(42)
#backbone <- ape::compute.brlen(ape::stree(2^power, type="balanced"), method=1.5)
backbone <- geiger::drop.extinct(geiger::sim.bdtree(b=1, d=0.2, stop="time", t=4.5, extinct=FALSE,seed=42))
backbone$tip.label <- paste0("t", sequence(ape::Ntip(backbone)))
#backbone <- ape::compute.brlen(ape::stree(2^power, type="balanced"), method=2)

bb1 <- backbone
bb2 <- backbone
phy1$tip.label <- paste0("p", phy1$tip.label)
phy2$tip.label <- paste0("p", phy1$tip.label)

starting_ntip <- ape::Ntip(backbone)
for (i in sequence(starting_ntip)) {
 bb1 <- ape::bind.tree(bb1, phy1, where=which(bb1$tip.label==paste0("t",i)))
 bb2 <- ape::bind.tree(bb2, phy2, where=which(bb2$tip.label==paste0("t",i)))
}

print(phytools::bd(ape::birthdeath(bb1)))
```

```{r backboneplotdetail, fig.height=3}
par(mfrow=c(1,2))
plot(phy1, show.tip.label=FALSE, main="Detail balanced")
plot(phy2, show.tip.label = FALSE, direction="leftwards", main="Detail pectinate")
```

```{r backboneplot, fig.height=7}
par(mfrow=c(1,2))
plot(bb1, show.tip.label=FALSE, main="Full balanced")
plot(bb2, show.tip.label=FALSE, direction="leftwards", main="Full pectinate")
```

And the lineage through time plots are the same for both trees (red and black lines, respectively)

```{r ltt}
ltt.plot(bb1, col="red", lwd=10)
ltt.lines(bb2, lwd=4, lty="dotted")
```

We can fit a few models to these trees

```{r fitbd, eval=TRUE}
bd.results <- data.frame(model=c("Yule", "BD", "MiSSE 1", "MiSSE 2"), balanced=NA, pectinate=NA)
bb1_yule <- ape::yule(bb1)
bb2_yule <- ape::yule(bb2)

bd.results[1,"balanced"] <- -TreePar::LikConstant(bb1_yule$lambda, 0, 1, TreeSim::getx(bb1))
bd.results[1,"pectinate"] <- -TreePar::LikConstant(bb2_yule$lambda, 0, 1, TreeSim::getx(bb2))

bb1_bd <- phytools::bd(ape::birthdeath(bb1))
bb2_bd <- phytools::bd(ape::birthdeath(bb2))
bd.results[2, "balanced"] <- -TreePar::LikConstant(bb1_bd["b"], bb1_bd["d"], 1, TreeSim::getx(bb1))
bd.results[2, "pectinate"] <- -TreePar::LikConstant(bb2_bd["b"], bb2_bd["d"], 1, TreeSim::getx(bb2))


# 
# 
# # From castor documentation
# PDR_function = function(ages,params){
# 	return(params['A']*exp(-params['B']*ages));
# }
# rholambda0_function = function(params){
# 	return(params['rholambda0'])
# }
# 
# age_grid = seq(from=0, to=max(branching.times(bb1)), length.out=100)
# 
# 
# fit_castor <- function(tree) {
#     return(castor::fit_hbd_pdr_parametric( tree,
#                     param_values  = c(A=NA, B=NA, rholambda0=NA),
#                       param_guess   = c(1,0,1),
#                       param_min     = c(-10,-10,0),
#                       param_max     = c(10,10,10),
#                       param_scale   = 1, # all params are in the order of 1
#                       PDR           = PDR_function,
#                       rholambda0    = rholambda0_function,
#                       age_grid      = age_grid,
#                       Ntrials       = 10,    # perform 10 fitting trials
#                       Nthreads      = 2,     # use 2 CPUs
#                       max_model_runtime = 1, # limit model evaluation to 1 second
#                       fit_control       = list(rel.tol=1e-6)))
#   }
# 
# bd.results[3, "balanced"] <- fit_castor(bb1)$loglikelihood
# bd.results[3, "pectinate"] <- fit_castor(bb2)$loglikelihood

misse.bb1.1param <- hisse::MiSSE(bb1, turnover=c(1), eps=c(1))
misse.bb2.1param <- hisse::MiSSE(bb2, turnover=c(1), eps=c(1))


bd.results[3, "balanced"] <- misse.bb1.1param$loglik
bd.results[3, "pectinate"] <- misse.bb2.1param$loglik

misse.bb1.2param <- hisse::MiSSE(bb1, turnover=c(1,2), eps=c(1,2))
bd.results[4, "balanced"] <- misse.bb1.2param$loglik
misse.bb2.2param <- hisse::MiSSE(bb2, turnover=c(1,2), eps=c(1,2))
bd.results[4, "pectinate"] <- misse.bb2.2param$loglik


#misse.bb1.1.5param <- hisse::MiSSE(bb1, turnover=c(1,2), eps=c(1,1))
#bd.results[5, "balanced"] <- misse.bb1.1.5param$loglik
#misse.bb2.1.5param <- hisse::MiSSE(bb2, turnover=c(1,2), eps=c(1,1))
#bd.results[5, "pectinate"] <- misse.bb2.1.5param$loglik
```

```{r missetable, eval=TRUE}
knitr::kable(bd.results)
```

```{r ancrecon, eval=TRUE}
misse.recon1.2param <- hisse::MarginReconMiSSE(bb1,f=1, pars=misse.bb1.2param$solution, hidden.states=2)
misse.recon2.2param <- hisse::MarginReconMiSSE(bb2,f=1, pars=misse.bb2.2param$solution, hidden.states=2)
save(list=ls(), file="Appendix1.rda")

```

```{r plotrecon, message=FALSE, eval=TRUE}
plot.misse.states(misse.recon1.2param, show.tip.label=FALSE, legend="none")
plot.misse.states(misse.recon2.2param, show.tip.label=FALSE, legend="none")
```
