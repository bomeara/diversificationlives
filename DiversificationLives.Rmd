---
title: "Diversification Lives"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache=TRUE)
```

Using modern phylogenies as a time machine to look into the past has long been popular. The simplest case is ancestral state reconstruction. Given a trait, such as body size, and a simple model, such as Brownian motion, and a tree with branch lengths in units of time, one can chart many species occuring through the past. For example, just a 100 observations in the present, with a tree, can result in 99 inferences of states at nodes, an inference of a rate of evolution, and states all along the branches. 

Rather than simple Brownian motion, one could add a trend: not only are species evolving with random motion (as expected under the central limit theorem) but there could also be a gradual increase in size. This model adds just one more parameter over the standard Brownian motion model, and it again allows infernce of states at internal nodes and along branches. The problem is that Brownian motion with a trend and without a trend have, on chronograms of just extant taxa, exactly equal likelihoods. They are thus indistinguishable based on likelihood score alone -- that is, they both predict present data equally well. The no trend model has one fewer parameters, but one could create an alternate "simple" model that had a default trend of an increase by 17 every million years: then the only way to have no trend would be to estimate a trend parameter of -17 per million years. And which model we use can have a dramatic effect on ancestral state reconstructions: the ancestor of a clade of taxa with traits ranging from 10-12 might have a reconstructed state near 11 under a no trend model, but could have a reconstructed state of 50 under a model with a negative trend through time.

One approach to dealing with this would be to throw up our hands and give up on models of trait evolution. After all, if there can be models that give different ancestral states and the same likelihood given trees of modern taxa, can we really learn anything by using them?

In practice, however, we know we can learn about character evolution from models such as Brownian motion, even though several models can give the same likelihoods (the single linear trend model is just one example of the possibilities). For example, to look at correlations of two traits, we can use independent contrasts (Felsenstein 1985), to reconstruct direction and magnitude of changes: for two descendant branches of a node, if the right branch gets bigger for trait X than its left sister does, does it also tend to get bigger for trait Y? Even though this method reconstructs traits using Brownian motion, the inability to distinguish trait models from non-trait models does not interfere in our ability to look at trait correlation. We can also care about parameters of the models themselves rather than the inference of states through all time: do certain events cause an increase in the rate of evolution, for example (Garland, 1992; O'Meara et al. 2006)? We might rightly shy away from trying to estimate all ancestral states (though there are exceptions _____), but we can still use these methods if we do not ask them to give more information than they can.

Louca and Pennell (2020) show the same issue with diversification models. Mathematically, we know we can reconstruct a single birth and a single death rate over an entire tree (Nee, Kubo & Iwasa.....) but empirically it can be hard to get precise estimates. We know we cannot estimate all of a single birth, death, and sampling rate (Stadler...) -- there is a ridge such that there is no unique set of values that gives a better probability of the tree than any other set. Kubo and Iwasa (1995) showed that with linear change models in birth and/or death rate, there are an infinite set of models with equal likelihoods. However, the field has grown to focus on doing the equivalent of ancestral state reconstruction but for diversification: rather than tracing the smoothly changing ancestral states of taxa all along branches, we try to reconstruct the two seismograph-like lines showing speciation and extinction rates scrolling into the past: a sudden sweep up of the extinction rate arm here means a mass extinction, a slow downward movement of the speciation rate arm as one approaches the present could mean available niches are becoming filled up, limiting the possibilities of speciation. There are many methods that take the tree as an input and output these diversification seismographs. They often limit how the arms can move in various ways: some stick the extinction rate arm at zero, despite the abundant evidence of extinction; others estimate one position for that arm for all time; some let the speciation arm only move along a logistic path; some hold the speciation arm constant and let the extinction arm jerk up and down at mass extinctions (Moore). These all give arresting images of how rates have changed through time, sometimes shown as lines jiggling through time, other times shown as a tree with a stunning blue to red gradient showing hot spots of evolution.

Louca and Pennell (2020) argue that because these methods can take the same input data (the timing of branching events on the tree) and predict it equally well with different curves, there is a problem. We agree. Others have interpreted this as a signal to give up on the analysis of diversification using phylogenies of modern species alone. We feel that this is as intemperate as giving up all studies of trait evolution because different models can give the same likelihood of modern data but different ancestral states. 

Louca and Pennell's solution is to break off both arms of the diversification seismograph and give us a new one in their place: the pulled diversification rate. It is important to note this is not simply the diversification rate (speciation rate minus extinction rate) at any one time, but an effective diversification rate if we were to assume speciation rate was time-independent, something much harder to interpret. However, their goal is still to trace the scratchings of the diversification seismograph back through time, just using their single new arm. It would be the equivalent of a population geneticist saying that many models can give the same gene trees, so we need to estimate just effective population size, but we can fit the motions of this Ne fully from the observed samples until they all coalesce. Tracing these scratchings through time remains a difficult issue: with, say, 87 coalescent samples one would not want to try to estimate the effective population size as it fluctuates through time. Instead, one might ask about things like does Ne increase with aridification forming sky islands: test a hypothesis with a model and its parameter estimates. Oddly, the pulled diversification rate solution leaves us with an arm that can jiggle at will, and Louca and Pennell still see this plotting of the curve as the goal (supplement S2). They also disagree with any idea of choosing the simplest model possible given the data. 

Another issue plagueing the field of diversification seismograph studies is ignoring uncertainty. Nee clearly showed substantial uncertainty. Most analyses doing the sort of work Louca and Pennell criticize return a single line for each parameter, presented with no uncertainty. This ignoring uncertainty might have contributed to the field whistling past this problem in the past. Louca and Pennell's analyses in this paper, and in other work using pulled diversification rate (...check..) also present the point estimate of the single line rather than show the uncertainty, and their software has no built in function to even calculate the uncertainty.

Rather than trace the scratchings of a single pulled diversification rate arm, or both speciation and extinction rate arms, on a diversification seismograph, or take the extreme step of stopping all analyses of diversification using modern phylogenies, we would argue that we should use the methods we have to answer biological questions, in the same way we can use Brownian motion or coalescent models even though different parameterizations can give identical likelihoods. 

Another criticism of diversification reconstruction as a goal is the missing taxa. Modern crocodylians are ambush predators, but extinct lineages including active hunters, galloping after prey across Australia. Trying to understand diversification dynamics of crocodylians in the past using only the paraphyletic set of survivors, where entire diverse clades of the past have no descendants, is difficult. It is the same as trying to understand the size of birds in the Cretaceous using only information from the lineages that survived to the present. However, phylogenies can give us information about what led to present diversity. We can see what traits are associated with modern diversity, and maybe when certain modern lineages took off, but we have to understand that it is using the past to understand the present survivors, not using present survivors to understand the past. 

First, SSE models appear fine. 

Overfitting is still an issue under the pulled diversification approach. For example, Louca and Pennell used AIC to select the number of regimes in their seed plant reconstruction, and sensibly did not start reconstructing at the root where there are very few taxa. However, fully half the rate estimates came from the portion of the tree with fewer than ... taxa. With rate regimes, the main signal for rates in a regime come from the timing of splits within that regime: a 1,000,000 taxon tree only provided ... datapoints for the first rate, ... datapoints for the second rate, etc. We advocate using an equal number of points in each regime, rather than equal time. For a diversification model, over half the data are events leading to modern species (in a balanced tree, N/2 node heights lead to modern species; in a pectinate tree, N-1 nodes have at least one modern descendant). We are tempted to look at rates reconstructed halfway up the tree, but the reality is that these models are largely fitting data far more recent than that.







There has long been a debate in phylogenetics about the possibility of estimating speciation and extinction rates from trees of extant species. Nee et al. (1994) showed that, mathematically, both rates could be estimated; Kubo and Iwasa (1995) showed that estimation of extinction rate had high uncertainty and that an infinite array of models with gradually changing speciation and/or extinction rates would be indistiguishable; Rabosky (___) showed that a constant rate model could get bad estimates if the true model were one with rapidly changing speciation rates; Beaulieu and O'Meara (__) showed that for more biologically plausible models and large enough trees that a constant rate model could still work. There are a wide variety of papers developing models that seek to fit changing speciation or extinction rates using modern trees (___), some, given the empirical difficulties in estimating extinction rates, seek to estimate just their difference, the diversification rate (_____), often by assuming extinction rate is constant. There are also a wide array of models that examine the correlation of traits with diversification, speciation, and/or extinction rates (______), collectively known as SSE models (for state speciation and extinction). There are over __,000 papers that cite these models.

Louca and Pennell (2020), and the Pagel (2020) commentary on this, put all of this enterprise in doubt. Formally, Louca and Pennell (2020) present a substantially similar argument, though much more detailed, to the one presented by Kubo and Iwasa (1995) a quarter century ago that for a given phylogeny, there are an infinite array of models that have speciation and/or extinction rate smoothly vary through time that can equally well fit the tree. Their solution is not to give up all analyses of how diversification has changed through time from modern chronograms, but instead use the pulled diversification rate to examine patterns of variation through time: look at one parameter that does not map to a biological process, in the same way that effective population size is a useful parameter in population genetics that does not map directly to a readily observable biological estimate like census population size. However, the popular interpretation of their work, assisted by reviews such as Pagel (2020), is that any attempt to learn about diversification from modern chronograms is futile. This interpretation is not correct.

We focus here on SSE models. These models are known to have issues. Maddison and FitzJohn (2015) show that single changes in characters may be overinterpreted as showing strong evidence for a diversification pattern change. If a tree evolves under a process where diversification patterns may change on some branches, these methods may try to correlate these changes with a character if forced to choose between that and an incorrect model of homogeneous patterns (Rabosky and Golberg (); Beaulieu and O'Meara ()), though this may reflect more misapplication of statistics by biologists than a flaw in the methods per se (Beaulieu and O'Meara ()). There might need to be a lot of data to infer rates accurately (Davis ()). There are approaches that can deal with some of these issues: check to see if there is a consistent diversification pattern across trait origins (Beaulieu achene), provide rich models that allow rate variation not to be shoehorned into available characters (hisse___, geohisse__), etc. But what does this new work suggest for these?

In fact, the possibility of trait-dependent diversification models still working is left unresolved (Louca and Pennell (2020), S.6) -- the authors believe the chance of identifiability is slim but acknowledge this is not proven. It could be worth distinguishing the methods that are weeds from those that are useful before burning a field to the ground.

For models that do not change speciation and extinction over time, there is a well-behaved likelihood surface (Nee et al. 1994), complete with a peak. 

```{r plotsurface, warning=FALSE, fig.cap="Likelihood surface for constant rate birth death model from four simulations with the same parameters. Birth rate = 0.4, death rate = 0.2, total time of 20. The black dot shows the maximum likelihood point; The open circle shows the true generating values; the red contour line shows all the points within 2 lnL units of the best point. Other contour lines are 1, 5, and 10 lnL units away from the optimum"}
library(geiger)
library(TreePar)
library(ggplot2)
library(phytools)
library(gridExtra)
library(metR)

true.b <- 0.4
true.d <- 0.2
true.netdiv <- true.b - true.d
true.ef <- true.d/true.b
npoints <- 51
maxtime <- 20

netdiv.vector <- seq(from=0, to=0.7, length.out=npoints)
ef.vector <- seq(from=0, to=1, length.out=npoints+1)
ef.vector <- ef.vector[-length(ef.vector)] #cout out exactly ef==1

seeds <- c(1831, 1836, 1839, 1859) # Darwin biography easter eggs; also makes sure we know what to expect consistently

SimAndPlot <- function(seed, netdiv.vector, ef.vector, maxtime) {

  results <- expand.grid(netdiv=netdiv.vector, ef=ef.vector, negloglikelihood=NA)
  
  results$b <- results$netdiv/(1-results$ef)
  results$d <- (results$netdiv*results$ef)/(1-results$ef)
  
  
  
  
  #library(interp)
  
  
  phy <- geiger::sim.bdtree(b=true.b, d=true.d, stop="time",t=maxtime, seed=seed)
  phy.pruned <- geiger::drop.extinct(phy)
  # b.vector <- seq(from=0,to=1, length.out=npoints)+1/(10*npoints) #offset just a smidge to deal with TreePar's failure to handle b==d
  # d.vector <- seq(from=0,to=1, length.out=npoints)
  # parameters <- expand.grid(b=b.vector, d=d.vector, negloglikelihood=NA)
  # parameters <- subset(parameters, b>0)
  x <- ape::branching.times(phy.pruned)
  for (i in sequence(nrow(results))) {
    results$negloglikelihood[i] <- TreePar::LikConstant(lambda=results$b[i], mu=results$d[i], sampling=1, x=x)
  }
  #results[!is.finite(results$negloglikelihood),] <- max(results$negloglikelihood, na.rm=TRUE)
  #p <- ggplot(parameters, aes(x=d, y=b, z=negloglikelihood)) + geom_contour_filled()
  # smooth it a bit -- handles the case of TreePar failing if b=d
  # parameters.smoothed <- akima::interp(parameters$b, parameters$d, parameters$negloglikelihood, xo=seq(min(parameters$b), max(parameters$b), length = 1000),
  #                    yo=seq(min(parameters$d), max(parameters$d), length = 1000))
  # parameters.df <- data.frame(b=parameters.smoothed$x, d=parameters.smoothed$y, negloglikelihood=parameters.smoothed$z)
  
    min.lik <- min(results$negloglikelihood, na.rm=TRUE)

  p <- ggplot(results) + theme(legend.position = "none") + coord_equal()
 # p <- p + geom_contour_filled(aes(x=ef, y=netdiv, z=negloglikelihood)) + scale_fill_viridis_d()
    #p <- p + geom_contour_filled(aes(x=ef, y=netdiv, z=negloglikelihood),  breaks=seq(from=2, to=10, length.out=50)+min.lik) + scale_fill_viridis_d()

  #p <- p + geom_contour_filled(aes(x=ef, y=netdiv, z=negloglikelihood),  bins=100) + geom_contour(aes(x=ef, y=netdiv, z=negloglikelihood), color="darkgray", bins=25)
  #p <- p + geom_contour_filled(aes(x=ef, y=netdiv, z=negloglikelihood),  bins=100)
  #p <- p + geom_contour(aes(x=ef, y=netdiv, z=negloglikelihood, color="black"), breaks=2+min(results$negloglikelihood))
    p <- p + geom_contour(aes(x=ef, y=netdiv, z=negloglikelihood), colour="darkgray", breaks=c(1,5,10)+min.lik)
     p <- p + geom_contour(aes(x=ef, y=netdiv, z=negloglikelihood), colour="red", breaks=c(2)+min.lik)
     
     

  #p <- p+annotate("text", x=true.ef, y=true.netdiv, label="T", color="red")
    p <- p+geom_point(aes( x=true.ef, y=true.netdiv, fill="blue"), shape=1)
    p <- p + xlim(min(results$ef), max(results$ef)) + ylim(min(results$netdiv), max(results$netdiv))
  #p <- p+annotate("text", x=results$ef[which.min(results$negloglikelihood)], y=results$netdiv[which.min(results$negloglikelihood)], label="*", color="white")
  p <- p+geom_point(aes( x=results$ef[which.min(results$negloglikelihood)], y=results$netdiv[which.min(results$negloglikelihood)], fill="white"))
  label.df <- data.frame(name=c("Truth", "MLE"), x=c(true.ef, results$ef[which.min(results$negloglikelihood)]), y=c(true.netdiv, results$netdiv[which.min(results$negloglikelihood)]), stringsAsFactors = FALSE)
  p <- p + ggtitle(paste0("Tree of ", ape::Ntip(phy.pruned), " taxa"))
  #p <- p + geom_text_repel(aes(x=x, y=y, label=name, color="white", segment.color = 'grey50'),data=label.df)
  p
}

p1 <- SimAndPlot(seed=seeds[1], netdiv.vector, ef.vector, maxtime)
p2 <- SimAndPlot(seed=seeds[2], netdiv.vector, ef.vector, maxtime)
p3 <- SimAndPlot(seed=seeds[3], netdiv.vector, ef.vector, maxtime)
p4 <- SimAndPlot(seed=seeds[4], netdiv.vector, ef.vector, maxtime)

grid.arrange(p1, p2, p3, p4, nrow=2)

# parameters$ef <- parameters$d/parameters$b
# parameters$netdiv <- parameters$b - parameters$d
# 
# parameters.truncated <- parameters
# parameters.truncated <- subset(parameters.truncated, ef<2)
# 
# q <- ggplot(parameters.truncated) + geom_point(aes(x=ef, y=netdiv))

# parameters.interp <- interp::interp(x=parameters$ef, y=parameters$netdiv, z=parameters$negloglikelihood, output = "points", xo=seq(from=0, to=2, length.out=npoints), yo=seq(from=min(parameters$netdiv), to=max(parameters$netdiv), length.out=npoints))
# parameters.interp.df <- data.frame(ef=parameters.interp$x, netdiv=parameters.interp$y, negloglikelihood=parameters.interp$z)
# 
# q <- ggplot(parameters.interp.df) + geom_contour_filled(aes(x=ef, y=netdiv, z=negloglikelihood),  bins=25) + geom_contour(aes(x=ef, y=netdiv, z=negloglikelihood), color="darkgray", bins=100)

#+ geom_contour(aes(x=d, y=b, z=negloglikelihood), color="red", breaks=2+min(parameters.interpt.df$negloglikelihood)) + theme(legend.position = "none") + coord_equal()
#q <- q+annotate("text", x=true.d, y=true.b, label="Truth", color="white")
#q <- q+annotate("text", x=parameters$d[which.min(parameters$negloglikelihood)], y=parameters$b[which.min(parameters$negloglikelihood)], label="MLE", color="white")
print(q)
```

As shown by the Fig. 1 (which mimics a similar one by Nee et al. 1994), there is a well-defined peak, albeit substantial uncertainty in extinction fraction: not surprising, given the size of these trees. The identifiability issues of models that allow speciation and/or extinction rates to gradually change have also long been known, but sadly ignored. Kubo and Iwasa (1995) showed that a gradual speciation rate change model with constant extinction rate could produce the same lineage through time curve as a constant speciation rate model with gradual extinction rate change, but, rather than just presenting this troubling special case, as their work was categorized by Louca and Pennell (2020), they explicitly state that "There are infinitely many cases intermediate between these two that also generate the same ln(N_t) pattern, in which both the branching rate and the extinction rate change with time." 

Louca and Pennell (2020) expand on the mathematical treatment of Kubo and Iwasa (1995). Louca and Pennell (2020) show that two models are "congruent if and only if they have the same r_p and the same lambda_p at some time point in the present or past (for example the same product rho*lambda_o)." Their pulled diversification rate is:



Their pulled diversification rate is (supplement equation 10):

r_p := lambda - mu + (d lambda / d T) / lambda

that is, the pulled diversification rate at a given time is equal to the normal estimate of diversification rate at that time plus the slope of how lambda changes with time divided by the value of lambda at that time. Lambda is the speciation rate at some time, which can change in their general model; in some equations this is represented as a single variable (i.e., supplement equation 10) but in other times a function of time (supplement equation 12). To make the derivation easier to follow we adopt the latter notation: lambda(u) is the speciation rate at time u in the past; the present is time 0. Rewriting the above equation using this notation:

r_p(u) := lambda(u) - mu(u) + (d lambda(u) / d T) / lambda(u)

Take the simplest case, as in Nee et al. (1995), of a set of models where (d lambda(u) / d T) is zero for all u (that is, where the speciation rate does not change with time), and assume mu(u) is also constant. In that case, r_p(u) := lambda(u) - mu(u) + 0 / lambda(u) = lambda(u) - mu(u). Two such models are congruent if and only if r_p(u)_modelA == r_p(u)_modelB and if lambda_p(u)_modelA == lambda_p(u)_modelB. The first requirement can be satisfied by any two models with the same net diversification rate; for example, take a Yule model (where mu(u)_modelA = 0 for all u) and a non-Yule model that may have the same net diversification rate (say, mu(u)_modelB = K > 0 for all u, so lambda(u)_modelA = lambda(u)_modelB - K). However, at the tip, rho * lambda(u)_modelA != rho * lambda(u)_modelB, so these models are not congruent: they will have different likelihoods on the same tree. They may be practically indistinguishable as the parameters of the two models grow similar (i.e., as K approaches zero) and for small datasets, but mathematically, they are different models. 

This is consistent with what we know from Nee et al. (1994), Stadler (___) and others, including Figure 1: given knowledge of sampling fraction, and the branch lengths of a tree, one can estimate speciation and extinction rate. 

However, that is not all this requirement shows. If a speciation rate through time has a slope of zero but sudden jumps, i.e., a sudden burst of speciation from 65 to 55 MYA, then the pulled diversification rate equals the unpulled diversification rate in that time interval. However, here there can be some congruent, but distinct models. For example, if model_A and model_B have the same flat speciation and extinction rates through all intervals but this one, and in that interval model_A is Yule and model_B is not Yule, then they could have the same net diversification rate in that interval, still have the same pulled speciation rate at the present, and thus be congruent. Referring back to classic LTT plots may help. Assume for all time intervals but that lambda(u)_modelA = lambda(u)_modelB = 0.4 and mu(u)_modelA = mu(u)_modelB = 0. In that time interval, modelA's rates don't change, but modelB has both its lambda and mu increase by 0.2. The slope of the lineage through time plot in that interval is still 0.4 (0.4 - 0 for modelA, 0.6 - 0.2 for modelB); the slope of the tangent to that plot is still 0.4 for them both at the present. So both models are congruent, fitting the same LTT plot. 

Where do SSE models fall into this? 



So, for the past quarter century, we should have known that attempting to estimate gradually changing speciation and/or extinction rates over trees leads to identifiability issues. And yet the field has merrily moved on with such methods (_____). How is this? One may be that this paper was largely overlooked: it has only 55 citations, and much citation seems to be regarding this paper as an early demonstration of the difficulty of estimating extinction rates on trees of extant taxa, which is indeed a main point. This paper is less pessimistic than Louca and Pennell (2020) or Pagel (2020), for example, showing that a discrete increase in speciation rate can be detected, perhaps another reason for ignoring its cautions. Another is that scientists have been willing to fix parameters to make models based on lineage through time data tractable, collapsing the model identifiability issue. Many early methods assumed extinction rate was zero (___), despite spectactular counterexamples (__Irish elk__). Later methods allowed extinction rate to be higher than zero, but constant over time (____), or, less commonly, fixed speciation rate as constant but allowed extinction to vary (___). This has led to to a focus on net diversification or speciation since they are easier to estimate and more typically allowed to vary, even though there is ample evidence that extinction rate can vary dramatically and importantly. 

However, all the caveats raised by Kubo and Iwasa (1995) and Louca and Pennell (2020) apply to models with at least one of speciation or extinction rates smoothly varying over the tree, with every taxon at a given time point experiencing the same rates. [Note that Kubo and Iwasa (1995), do caution about the practical difficulties of estimating extinction rate as well, even in the constant case]. We do know unchanging speciation and extinction rates are identifiable (___). Adding unknown sampling fraction (Stadler ___), makes it possible to estimate only two of speciation, extinction, or sampling fraction, but, of these, biologists may be most willing to use non-phylogenetic external estimates of sampling fraction. So, for a given tree with constant speciation and extinction rate and known sampling fraction, we can estimate these two rates. 

What about two trees? If for a single tree we can estimate speciation and extinction rates, surely we can repeat this for a different tree and get its own estimates. But of course, no trees are completely independent: they are subtrees of a larger tree. If we assume these two trees are sister clades, we can estimate one set of rates for the left clade and one for the right clade. 

```{r twotrees}
left <- geiger::sim.bdtree(b=true.b, d=0, stop="taxa",n=20, seed=1994)
left$tip.label <- gsub("s","A", left$tip.label)
right <- geiger::sim.bdtree(b=3*true.b, d=0, stop="taxa",n=20, seed=1995)
right$tip.label <- gsub("s","B", right$tip.label)

left$root.edge <- 0.1*max(branching.times(left))
right$root.edge <- max(branching.times(left)) - max(branching.times(right))
together <- ape::bind.tree(left, right)
tips <- c(rep(0, ape::Ntip(left)), rep(1, ape::Ntip(right)))
names(tips) <- c(left$tip.label, right$tip.label)
phytools::plotBranchbyTrait(together, tips, mode="tips", legend=FALSE)
```

Well then, what if we can take a chunk of one clade and put it on the other clade?  

```{r swap}
subclades.right <- phytools::getCladesofSize(right, clade.size=2)
chosen <- subclades.right[[which(lapply(subclades.right, ape::Ntip)==2)[1]]]
together.swap <- drop.tip(together, chosen$tip.label)
chosen.depth <- max(branching.times(chosen))
together.swap <- ape::bind.tree(together.swap,chosen, where=which(together.swap$tip.label=="A7"), position=chosen.depth)
phytools::plotBranchbyTrait(together.swap, tips, mode="tips", legend=FALSE)
```

In theory, if we know the mapping, we can still estimate the speciation and extinction rates on the red and blue parts of the tree.

Now imagine a more complex mapping of traits on a tree:

```{r nni}
together.sse <- geiger::sim.bdtree(b=true.b, d=0, stop="taxa",n=40, seed=2007)
together.sse$tip.label <- sample(together$tip.label, size=length(together$tip.label), replace=FALSE)
phytools::plotBranchbyTrait(together.sse, tips, mode="tips", legend=FALSE)
```

If we have a perfect mapping of which parts are from which tree, we could separately estimate the speciation and extinction rates for each.

This is almost BiSSE (Maddison et al. 2007), but it requires a character model, as well.

BiSSE cases:

Two clades, one with zero, one with 1
One tree with all tips zero, but some transitions to state 1 internally


```{r treesim_discreteshift}
# library(diversitree)
# set.seed(2007)
# pars <- c(lambda0=0.4, lambda1=0.2, mu0=0.2, mu1=0, q01=0.1, q10=0.2)
# phy <- NULL
# while(is.null(phy)) {
#   phy <- tree.bisse(pars=pars, max.t=20, x0=0)
# }
library(TreeSim)
ntax=300
nsim=50
lambdaA <- rep(.3,3)
muA <- rep(.1,3)
offset <- .6
treeheight <- 20
lambdaB <- lambdaA
lambdaB[2] <- lambdaB[2] + offset
lambdaC <- lambdaA
lambdaC[2] <- lambdaC[2] + offset
lambdaD <- lambdaA
muB <- muA
muB[2] <- muB[2] + offset
muC <- muA
muD <- muA
muD[2] <- muA + .19
#muB[2] <- muB[2] + offset
frac=rep(1, length(lambdaA))
times <- c(0,.1,.2)*treeheight
complete <- FALSE
K=0
A <- sim.rateshift.taxa(n=ntax, numbsim=nsim, lambda=lambdaA, mu=muA, frac=frac, times=times, complete=complete, K=K)
B <- sim.rateshift.taxa(n=ntax, numbsim=nsim, lambda=lambdaB, mu=muB, frac=frac, times=times, complete=complete, K=K)
C <- sim.rateshift.taxa(n=ntax, numbsim=nsim, lambda=lambdaC, mu=muC, frac=frac, times=times, complete=complete, K=K)
D <- sim.rateshift.taxa(n=ntax, numbsim=nsim, lambda=lambdaD, mu=muD, frac=frac, times=times, complete=complete, K=K)
plot(x=c(-6,0), y=c(10,ntax), type="n", log="y", bty="n", xlab="time", ylab="N")
for (i in sequence(nsim)) {
  ltt.lines(A[[i]], col="gray")
  ltt.lines(B[[i]], col=rgb(0,0,1,.1))
  ltt.lines(C[[i]], col=rgb(1,0,1,.1))
  ltt.lines(D[[i]], col=rgb(1,1,0,.1))


}
abline(v=-times       )
print(data.frame(lambdaA=lambdaA, lambdaB=lambdaB, muA=muA, muB=muB, divA=lambdaA-muA, divB=lambdaB-muB))
# 
# phy <- sim.rateshift.taxa(100,numbsim,lambda=c(3,0.001),mu=c(0,0),frac=c(1,1), times=c(1,.5), complete=FALSE)[[1]]
# ltt.plot(phy, log="y")


```


```{r treesim_discreteshift2}
# library(diversitree)
# set.seed(2007)
# pars <- c(lambda0=0.4, lambda1=0.2, mu0=0.2, mu1=0, q01=0.1, q10=0.2)
# phy <- NULL
# while(is.null(phy)) {
#   phy <- tree.bisse(pars=pars, max.t=20, x0=0)
# }
library(TreeSim)
library(viridis)
ntax=400
nsim=100
min.plot.time <- -6
lambdaA <- rep(.5,3)
muA <- rep(.2,3)
offset <- .2
treeheight <- 20
lambdaB <- lambdaA
lambdaB[2] <- lambdaB[2] + offset
lambdaC <- lambdaA
lambdaC[2] <- lambdaC[2] + offset
lambdaD <- lambdaA
lambdaE <- lambdaA

muB <- muA
muB[2] <- muB[2] + offset
muC <- muA
muD <- muA
muD[2] <- muD[2] + offset
muE <- muA
muE[2] <- muE[2] - offset
#muB[2] <- muB[2] + offset
frac=rep(1, length(lambdaA))
times <- c(0,.1,.25)*treeheight
complete <- FALSE
K=0
A <- sim.rateshift.taxa(n=ntax, numbsim=nsim, lambda=lambdaA, mu=muA, frac=frac, times=times, complete=complete, K=K)
B <- sim.rateshift.taxa(n=ntax, numbsim=nsim, lambda=lambdaB, mu=muB, frac=frac, times=times, complete=complete, K=K)
C <- sim.rateshift.taxa(n=ntax, numbsim=nsim, lambda=lambdaC, mu=muC, frac=frac, times=times, complete=complete, K=K)
D <- sim.rateshift.taxa(n=ntax, numbsim=nsim, lambda=lambdaD, mu=muD, frac=frac, times=times, complete=complete, K=K)
E <- sim.rateshift.taxa(n=ntax, numbsim=nsim, lambda=lambdaE, mu=muE, frac=frac, times=times, complete=complete, K=K)

plot(x=c(-.4+min.plot.time,0), y=c(10,ntax), type="n", log="y", bty="n", xlab="time", ylab="N")
A.ltt <- lapply(A, ltt.plot.coords)
B.ltt <- lapply(B, ltt.plot.coords)
C.ltt <- lapply(C, ltt.plot.coords)
D.ltt <- lapply(D, ltt.plot.coords)
E.ltt <- lapply(E, ltt.plot.coords)

interpolate.points <- function(x, timepoint) {
  matches <- which(x[,'time']<=timepoint)
  return(unname(x[max(matches), 'N']))
}

interpolate.all <- function(timepoint, list.ltt, fn=median) {
  values <- simplify2array(lapply(list.ltt, interpolate.points, timepoint=timepoint))
  return(fn(values))
}

plot.intervals <- seq(from=min.plot.time, to=0, length.out=1001)

lines(x=plot.intervals, y=sapply(plot.intervals, interpolate.all, list.ltt=A.ltt), col="black")
lines(x=plot.intervals, y=sapply(plot.intervals, interpolate.all, list.ltt=B.ltt), col=viridis(7)[2])
lines(x=plot.intervals, y=sapply(plot.intervals, interpolate.all, list.ltt=C.ltt), col=viridis(7)[3])
lines(x=plot.intervals, y=sapply(plot.intervals, interpolate.all, list.ltt=D.ltt), col=viridis(7)[4])
lines(x=plot.intervals, y=sapply(plot.intervals, interpolate.all, list.ltt=E.ltt), col=viridis(7)[5])
text(x=min.plot.time,y=interpolate.all(min.plot.time, A.ltt), labels="baseline",pos=2, cex=0.3)
text(x=min.plot.time,y=interpolate.all(min.plot.time, B.ltt), labels="b+,d+",pos=2, cex=0.3)
text(x=min.plot.time,y=interpolate.all(min.plot.time, C.ltt), labels="b+",pos=2, cex=0.3)
text(x=min.plot.time,y=interpolate.all(min.plot.time, D.ltt), labels="d+",pos=2, cex=0.3)
text(x=min.plot.time,y=interpolate.all(min.plot.time, E.ltt), labels="d-",pos=2, cex=0.3)
# for (i in sequence(nsim)) {
  # ltt.lines(A[[i]], col=viridis(5)[1])
  # ltt.lines(B[[i]], col=viridis(5)[2])
  # ltt.lines(C[[i]], col=viridis(5)[3])
  # ltt.lines(D[[i]], col=viridis(5)[4])
  # ltt.lines(E[[i]], col=viridis(5)[5])


# }
abline(v=-times       )
print(data.frame(lambdaA=lambdaA, lambdaB=lambdaB, lambdaC=lambdaC, lambdaD=lambdaD, lambdaE=lambdaE, muA=muA, muB=muB, muC=muC, muD=muD, muE=muE))
# 
# phy <- sim.rateshift.taxa(100,numbsim,lambda=c(3,0.001),mu=c(0,0),frac=c(1,1), times=c(1,.5), complete=FALSE)[[1]]
# ltt.plot(phy, log="y")


```

Take two distributions, say uniform over -1, 1 and a standard normal with mean 0 and sd=1. They have the same expectation. Therefore, by the reasoning of Louca and Pennell, they are congruent models. However, for a given string of data, say -0.3, .7, .9, the likeihoods of the data are very distinguishable, and we can easily tell the models apart.

The same thing occurs with diversification model. Here, for models with speciation and extinction rates homogenous across taxa (__ and Stadler), the information of the number of lineages over time contains all the information available. L&P say two models are congruent if they generate the same deterministic LTT, and that they will create the same likelihood for the same dataset. Empirically and theoretically that is not true. 

| Method | References | Louca and Pennell issue | Other issue|
| ------ | -- | --| -- | -- |

Steaman tree. Fit with mu = 0.9 lambda and mu=0, use castor, use also discrete slicing

Check: is this only a problem if there are shifts in rate within a single ltt plateau (going from N to N+1 species), where it's not identifiable

Louca and Pennell extended Fig 3a: they somehow smooth the LTT plot

Lambert and Stadler (2013) show that models with trait-affected diversification can't be described as a coalescent point process, aka LTT.

I do castor first, jeremy does discrete shift

I do castor on smith and brown seed plant like their extended 5h, also look at turnover and ef -- are they the same

It could be models are unidentifiable if there's not a tip with the regime : can't estimate speciation and extinction if there's not a tip with both parameters? But the sims above suggest this isn't the case


## Other stuff

Brownian motion is at the heart of many comparative methods: independent contrasts, ancestral state reconstruction, and more rely on this model. Evolutionary trends are long a topic of great interest in comparative methods: horses getting bigger with fewer toes, evolutionary arms races between predators and prey, and more. It is trivial to add a parameter to Brownian motion models to allow for the mean to evolve along a trend; the likelihood for such models given actual data is finite, and the simple no trend model is even nested within the trend model, so comparisons between a trend and no trend model is very easy. One could do a lot of great biology if you could compare these models on trees of modern taxa, but it's impossible: the likelihood of any trend model on a tree with equal root to top lengths for all taxa is exactly identical. So much as we might want to use this, these models are not identifiable for these kinds of trees.

However, it's a long way from saying these models aren't identifiable to saying any model using Brownian motion is impossible to use on trees of modern taxa. We can compare Brownian motion models with more complex models that are identifiable, such as Ornstein-Uhlenbeck models, Brownian models with more than one rate, models where the rate changes over time, and much more. So yes, Brownian motion with a trend models are unidentifiable on chronograms of modern taxa, but we do not say that any model that attempts to estimate rates of evolution on such trees are impossible. Some models in this space give the same likelihoods and cannot be distinguished, but many others can -- this calls for care and analysis, not panic.
